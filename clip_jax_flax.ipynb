{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b9oWlBnpb9Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlVdD78PCaz8"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n",
        "# Note: wheels only available on linux.\n",
        "!pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax -U\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "CsDH-fIjCnBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jax setup for colab"
      ],
      "metadata": {
        "id": "bUOsgbFBThfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/google/flax/issues/2263#issuecomment-1173424293\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  import jax.tools.colab_tpu\n",
        "  jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "v6w1d-63ThC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset download\n",
        "https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/"
      ],
      "metadata": {
        "id": "W7a-hZSKcrJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip"
      ],
      "metadata": {
        "id": "XU6GsgFpCyUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip"
      ],
      "metadata": {
        "id": "sAf8igWsch9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Flickr8k_Dataset.zip"
      ],
      "metadata": {
        "id": "tmC91GQMcv5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Flickr8k_text.zip"
      ],
      "metadata": {
        "id": "tvOmtmAVcz6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "9MD4drVHWRIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "g-Ry9l_7FdS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image"
      ],
      "metadata": {
        "id": "MGmgWg0cHFv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import cv2\n",
        "from transformers import AutoTokenizer\n",
        "from skimage import io\n",
        "import os\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "0yEhegGTWSKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "Fw-hNn-JXyFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_encoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "metadata": {
        "id": "Esyn8QX6YEnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\"I am a sentence for which I would like to get its embedding.\"]"
      ],
      "metadata": {
        "id": "89ueqH1aZIm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed = sentence_encoder(message)"
      ],
      "metadata": {
        "id": "pb6awyhJZM-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'embed: {embed.shape}')\n",
        "print(f'type: {type(embed)}')"
      ],
      "metadata": {
        "id": "ZjS54Y7tRaQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_np = np.array(embed)"
      ],
      "metadata": {
        "id": "KcjeI5hIZV9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'type: {type(embed_np)}')"
      ],
      "metadata": {
        "id": "L0gO8FP1SFDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'embed: {\", \".join(map(str, list(np.squeeze(embed_np)[:3])))}, ...')"
      ],
      "metadata": {
        "id": "tKA0ZQpraGTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-process captions\n",
        "\n",
        "* lower letters\n",
        "* punctuation"
      ],
      "metadata": {
        "id": "XlxmPH6o5ZyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "captions = []\n",
        "with open('Flickr8k.token.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        elems = line.split('\\t')\n",
        "        fn_id = elems[0].split('#')  # [filename, id]\n",
        "        captions.append(fn_id + [elems[1].lower()])  # [[filaneme, id, caption], ...]"
      ],
      "metadata": {
        "id": "eesC9A005sEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_caption = pd.DataFrame(captions, columns=['image_filename', 'id', 'caption'])"
      ],
      "metadata": {
        "id": "8w5iJ5Q-58SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Unique images: {len(np.unique(df_caption.image_filename.values))}')\n",
        "print(f'Total captions: {len(df_caption)}')"
      ],
      "metadata": {
        "id": "G8S8D5ewCAvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = str.maketrans('', '', string.punctuation)\n",
        "def remove_punctuation(text):\n",
        "  return text.translate(translator)"
      ],
      "metadata": {
        "id": "pWIeB47WMg9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = df_caption['caption'].iloc[0]\n",
        "print(f'original: {text}')\n",
        "print(f'removed: {remove_punctuation(text)}')"
      ],
      "metadata": {
        "id": "f66uOWqRNffj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "  cleaned_text = remove_punctuation(text)\n",
        "  return cleaned_text"
      ],
      "metadata": {
        "id": "0dAvLk4COlcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, caption in enumerate(df_caption.caption.values):\n",
        "  cleaned_caption = clean_text(caption)\n",
        "  df_caption['caption'].iloc[i] = cleaned_caption"
      ],
      "metadata": {
        "id": "Es_HKBz9Os-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_caption_0 = df_caption.loc[df_caption['id'].values == '0', :]"
      ],
      "metadata": {
        "id": "z0oL9NZrQepc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_filenames = df_caption_0.image_filename.values\n",
        "captions = df_caption_0.caption.values"
      ],
      "metadata": {
        "id": "qNCw1Ap9RgoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max([len(c.split()) for c in captions])"
      ],
      "metadata": {
        "id": "1NoB-uclDl3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'max_length: {max_length}')"
      ],
      "metadata": {
        "id": "dvOuoyYmD3jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{image_filenames[0]}: {captions[0]}')"
      ],
      "metadata": {
        "id": "lVdZ8FnNSEE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "ESH67VNZUBB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CLIPDataset(torch.utils.data.DataLoader):\n",
        "  def __init__(self, root_dir, image_files, captions, max_length, tokenizer=None, transforms=None):\n",
        "    self.image_files = [os.path.join(root_dir, f) for f in image_files]\n",
        "    self.captions = captions\n",
        "    self.max_length = max_length\n",
        "    self.tokenizer = tokenizer if tokenizer is not None else AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_file, caption = self.image_files[index], self.captions[index]\n",
        "    tokens = self.tokenizer(caption, truncation=True, padding=\"max_length\", max_length=self.max_length)\n",
        "    image = io.imread(image_file)\n",
        "    if self.transforms:\n",
        "      image = self.transforms(image)\n",
        "    return image, tokens\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_files)"
      ],
      "metadata": {
        "id": "SyTE_t91c7QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clip_dataset = CLIPDataset(\n",
        "    root_dir='Flicker8k_Dataset',\n",
        "    image_files=image_filenames,\n",
        "    captions=captions,\n",
        "    max_length=max_length,\n",
        "    transforms=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "rRFTTHvEJoij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image encoder"
      ],
      "metadata": {
        "id": "F6kCSZqtAK1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "9yMCroDrALzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm"
      ],
      "metadata": {
        "id": "fAwkC-nBCrpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('resnet50', pretrained=True, num_classes=0)"
      ],
      "metadata": {
        "id": "NInurUCxCy8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o = model.forward(torch.randn(2, 3, 299, 299))"
      ],
      "metadata": {
        "id": "d3cuiQuIC3A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'resnet50 feature: {o.shape}')"
      ],
      "metadata": {
        "id": "C_ouQfGbDC9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageEncoder(torch.nn.Module):\n",
        "  def __init__(self, model_name, pretrained=True, num_classes=0):\n",
        "    self.model = timm.create_model(\n",
        "        model_name=model_name, pretrained=pretrained, num_classes=num_classes\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "BRis_9xVDmtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text encoder"
      ],
      "metadata": {
        "id": "QYDg3bDMQJ__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    self.sentence_encoder = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    embed_np = np.array(self.sentence_encoder(x))\n",
        "    return embed_np"
      ],
      "metadata": {
        "id": "XnRTheQCQLGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projection head"
      ],
      "metadata": {
        "id": "3D8kG-AtzbDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionHead(torch.nn.Module):\n",
        "  def __init__(self, embed_dim, proj_dim, drop_ratio):\n",
        "    self.embed_dim = embed_dim\n",
        "    self.proj = nn.Linear(embed_dim, proj_dim)\n",
        "    self.gelu = nn.GELU()\n",
        "    self.fc = nn.Linear(proj_dim, proj_dim)\n",
        "    self.dropout = nn.Dropout(drop_ratio)\n",
        "    self.layer_norm = nn.LayerNorm(proj_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_proj = self.proj(x)\n",
        "    x = self.gelu(x_proj)\n",
        "    x = self.fc(x)\n",
        "    x = self.dropout(x)\n",
        "    x = x + x_proj\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "iQRXzqlJzdKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}