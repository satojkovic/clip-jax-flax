{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9dqV58hM2NN"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers\n",
        "!pip install git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "gVgSnr2FNADw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Lightning-AI/lightning.git"
      ],
      "metadata": {
        "id": "taYkRquANBMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations"
      ],
      "metadata": {
        "id": "Sf9jgWTiNIUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "pykSb_W3NDna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning"
      ],
      "metadata": {
        "id": "IPrB78wjNGMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A"
      ],
      "metadata": {
        "id": "sIhQhu2lNHkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image encoder\n",
        "\n",
        "Use FlaxResNetModel from huggingface transformers"
      ],
      "metadata": {
        "id": "aq81mz1_ePYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, FlaxResNetModel"
      ],
      "metadata": {
        "id": "cBnzAXGsePGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "Mvrk2jbPxYW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageEncoder(nn.Module):\n",
        "  def __init__(self, model_name: str, pretrained: bool = True, trainable: bool = True):\n",
        "    super().__init__()\n",
        "    self.model = FlaxResNetModel.from_pretrained(model_name)\n",
        "    self.image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    inputs = self.image_processor(images=x, return_tensors='np')\n",
        "    outputs = self.model(**inputs)\n",
        "    return outputs.pooler_output"
      ],
      "metadata": {
        "id": "dltZZaDdy2uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Encoder"
      ],
      "metadata": {
        "id": "aAFyZIDbkZNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import FlaxAutoModel"
      ],
      "metadata": {
        "id": "0XLf6_9RmSpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "  def __init__(self, model_name: str, trainable: bool = True) -> None:\n",
        "    super().__init__()\n",
        "    self.model = FlaxAutoModel.from_pretrained(model_name)\n",
        "    self.target_token_idx = 0\n",
        "\n",
        "  def __call__(self, input_ids, attention_mask):\n",
        "    output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    last_hidden_state = output.last_hidden_state\n",
        "    return last_hidden_state[:, self.target_token_idx, :]"
      ],
      "metadata": {
        "id": "sh_35cIHkaNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projection Head"
      ],
      "metadata": {
        "id": "4RXuFxEFydaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionHead(nn.Module):\n",
        "  def __init__(self, embedding_dim: int, projection_dim: int, dropout: float) -> None:\n",
        "    super().__init__()\n",
        "    self.projection = nn.Dense(projection_dim)\n",
        "    self.gelu = nn.gelu()\n",
        "    self.fc = nn.Dense(projection_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.layer_norm = nn.LayerNorm()\n",
        "\n",
        "  def __call__(self, x):\n",
        "    projected = self.projection(x)\n",
        "    x = self.gelu(projected)\n",
        "    x = self.fc(x)\n",
        "    x = self.dropout(x)\n",
        "    x += projected\n",
        "    return self.layer_norm(x)"
      ],
      "metadata": {
        "id": "c5PT-D06yemQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}